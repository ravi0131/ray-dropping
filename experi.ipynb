{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Beam-ID for all points in PandaSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# CONFIGURATION\n",
    "DATA_PATH = os.path.join('buni','dataset','pandaset')\n",
    "SCENE_IDX = 3\n",
    "FRAME_IDX = 70\n",
    "GROUND_LABELS = np.array([6, 7, 8, 9, 10, 11, 12, 34, 35, 37, 38, 39])\n",
    "user_home = os.path.expanduser('~') \n",
    "dataset_path = os.path.join(user_home,DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandaset import DataSet\n",
    "import logging\n",
    "\n",
    "dataset = DataSet(dataset_path)\n",
    "scenes_with_semantic_labels = sorted(dataset.sequences(with_semseg=True), key=int)\n",
    "print(f\"List of sequences available with semantic segmentation:\\n{scenes_with_semantic_labels}\")\n",
    "scene = dataset[scenes_with_semantic_labels[SCENE_IDX]]\n",
    "print(f\"Selected scene/sequence: {scenes_with_semantic_labels[SCENE_IDX]}\")\n",
    "scene.load_lidar()\n",
    "scene.load_semseg()\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.info(f\"Loaded scene {SCENE_IDX} with frame {FRAME_IDX}\")\n",
    "lidar_data = scene.lidar.data[FRAME_IDX]\n",
    "lidar_poses = scene.lidar.poses[FRAME_IDX]\n",
    "labels = scene.semseg.data[FRAME_IDX]\n",
    "\n",
    "from general_utils import pandaset_utils as pdutils\n",
    "from general_utils import gen_utils\n",
    "\n",
    "gen_utils.check_type(lidar_data,\"lidar_data\", logger)\n",
    "gen_utils.check_type(labels,\"labels\", logger)\n",
    "\n",
    "lidar_data, lidar_labels = pdutils.cleanup_lidar_data_and_labels(lidar_data, labels, lidar_poses,logger)\n",
    "\n",
    "logger.info(f\"Shape of lidar_data before reshaping: {lidar_data.shape}\")\n",
    "gen_utils.check_type(lidar_data,\"lidar_data\",logger)\n",
    "lidar_points = lidar_data.iloc[:,:3].to_numpy()\n",
    "lidar_points = lidar_points.astype('float64')\n",
    "logger.info(f\"Shape of lidar_data after reshaping: {lidar_points.shape}\")\n",
    "gen_utils.check_type(lidar_points,\"lidar_points\",logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cartesian_to_spherical(points):\n",
    "    \"\"\" Convert cartesian coordinates to spherical (azimuth and elevation angles) for multiple points \"\"\"\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2]\n",
    "    \n",
    "    azimuth = np.arctan2(x, y)  # Azimuth (horizontal angle) in radians\n",
    "    elevation = np.arctan2(z, np.sqrt(x**2 + y**2))  # Elevation (vertical angle) in radians\n",
    "    return azimuth, elevation\n",
    "\n",
    "def find_closest_channel(elevations, correction_table):\n",
    "    \"\"\" Match elevation angle to the closest laser channel for multiple points \"\"\"\n",
    "    vertical_angles = correction_table['Elevation'].to_numpy()\n",
    "    \n",
    "    # Find the index of the closest channel for each elevation\n",
    "    idx = np.abs(np.radians(vertical_angles).reshape(-1, 1) - elevations).argmin(axis=0)\n",
    "    \n",
    "    # Return channel IDs and the corresponding channel correction data\n",
    "    return correction_table.iloc[idx]\n",
    "\n",
    "def correct_azimuth(azimuths, azimuth_offsets):\n",
    "    \"\"\" Correct the azimuth angle using the provided offset for each channel \"\"\"\n",
    "    return azimuths - np.radians(azimuth_offsets)\n",
    "\n",
    "def assign_beam_ids(points, correction_table):\n",
    "    \"\"\" Assign the beam IDs to each point in the point cloud \"\"\"\n",
    "    \n",
    "    # Step 1: Convert Cartesian coordinates to Spherical\n",
    "    azimuths, elevations = cartesian_to_spherical(points)\n",
    "    \n",
    "    # Step 2: Find closest channel (vertical) for each point\n",
    "    closest_channels = find_closest_channel(elevations, correction_table)\n",
    "    \n",
    "    # Step 3: Correct azimuth for each point based on the closest channel's azimuth offset\n",
    "    corrected_azimuths = correct_azimuth(azimuths, closest_channels['Azimuth'])\n",
    "    \n",
    "    # Step 4: Extract channel IDs and return the assigned beam IDs\n",
    "    beam_ids = closest_channels['Channel'].to_numpy()\n",
    "    \n",
    "    return beam_ids, np.degrees(corrected_azimuths), np.degrees(elevations)\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def visualize_beam_ids(lidar_points, beam_ids):\n",
    "\n",
    "    # Create a point cloud in Open3D and assign colors based on beam IDs\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(lidar_points)\n",
    "\n",
    "    # Use a discrete colormap with enough unique colors\n",
    "    unique_beam_ids = np.unique(beam_ids)\n",
    "    n_unique_beam_ids = len(unique_beam_ids)\n",
    "\n",
    "    # Generate a colormap with N unique colors\n",
    "    colors_list = list(mcolors.CSS4_COLORS.values())  # Get a large list of CSS colors\n",
    "    if n_unique_beam_ids > len(colors_list):\n",
    "        raise ValueError(\"Not enough unique colors available. Increase the color list or choose another colormap.\")\n",
    "\n",
    "    # Create a color dictionary that maps each beam ID to a unique color\n",
    "    beam_id_to_color = {beam_id: colors_list[i % len(colors_list)] for i, beam_id in enumerate(unique_beam_ids)}\n",
    "\n",
    "    # Map the beam IDs to the corresponding colors\n",
    "    colors = np.array([mcolors.to_rgb(beam_id_to_color[beam_id]) for beam_id in beam_ids])\n",
    "\n",
    "    # Set the colors to the point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load angle correction file (replace with actual filename)\n",
    "corrections_file = os.path.join(os.getcwd(),'Pandar64_Angle_Correction_File.csv')\n",
    "corrections = pd.read_csv(corrections_file)\n",
    "beam_ids, _, _ = assign_beam_ids(lidar_points, corrections)\n",
    "\n",
    "visualize_beam_ids(lidar_points,beam_ids)\n",
    "\n",
    "lidar_points_with_beam_ids = np.hstack((lidar_points, beam_ids.reshape(-1, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray-Dropping\n",
    "\n",
    "+ `beam_ids` is a numpy array. \n",
    "+ Joint `beam_ids` with `lidar_points` to get `lidar_points_with_beam_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_beam_drop(points):\n",
    "    # Randomly select a beam drop ratio from [1, 2, 3]\n",
    "    beam_drop_ratio = np.random.choice([1, 2, 3])\n",
    "    # beam_drop_ratio = 3\n",
    "    print(f\"Beam drop ratio: {beam_drop_ratio}\")\n",
    "    # Randomly select a starting beam index\n",
    "    start_index = np.random.randint(0, beam_drop_ratio)\n",
    "\n",
    "    # Apply the ray-dropping condition\n",
    "    mask = (points[:, 3] - start_index) % beam_drop_ratio == 0\n",
    "    return points[mask]\n",
    "\n",
    "\n",
    "def spherical_coordinates_conversion(points):\n",
    "    # Convert to spherical coordinates\n",
    "    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "    radial_dist = np.sqrt(x**2 + y**2 + z**2)\n",
    "    theta = np.arctan2(y, x)  # azimuth\n",
    "    phi = np.arcsin(z / radial_dist)  # elevation\n",
    "\n",
    "    # Filter out points with radial distance < 0.1\n",
    "    valid_mask = radial_dist > 0.1\n",
    "\n",
    "    return np.vstack((theta[valid_mask], phi[valid_mask], radial_dist[valid_mask])).T, valid_mask\n",
    "\n",
    "def random_spherical_drop(points, valid_mask):\n",
    "    # Sample spherical resolutions for theta and phi\n",
    "    spherical_resolutions = np.random.choice([600, 900, 1200, 1500])\n",
    "    \n",
    "    # Convert theta and phi to grid cells\n",
    "    spherical_coords, valid_mask = spherical_coordinates_conversion(points)\n",
    "    theta_grid = (spherical_coords[:, 0] * spherical_resolutions).astype(int)\n",
    "    phi_grid = (spherical_coords[:, 1] * spherical_resolutions).astype(int)\n",
    "    \n",
    "    # Randomly sample spherical drop ratio\n",
    "    spherical_drop_ratio = np.random.choice([1, 2])\n",
    "    # spherical_drop_ratio = 2\n",
    "    print(f\"Spherical drop ratio: {spherical_drop_ratio}\")\n",
    "    # Apply the ray-dropping condition in the spherical coordinates\n",
    "    theta_mask = (theta_grid % spherical_drop_ratio == 0)\n",
    "    phi_mask = (phi_grid % spherical_drop_ratio == 0)\n",
    "    \n",
    "    # Combine the valid_mask from earlier with spherical mask\n",
    "    combined_mask = valid_mask & theta_mask & phi_mask\n",
    "    return points[combined_mask]\n",
    "\n",
    "\n",
    "def ray_dropping_augmentation(points):\n",
    "    # Step 1: Random beam drop\n",
    "    points_after_beam_drop = random_beam_drop(points)\n",
    "    \n",
    "    # Step 2: Spherical drop\n",
    "    points_after_spherical_drop = random_spherical_drop(points_after_beam_drop, np.ones(points_after_beam_drop.shape[0], dtype=bool))\n",
    "    \n",
    "    return points_after_spherical_drop\n",
    "\n",
    "# Example usage\n",
    "augmented_points_final = ray_dropping_augmentation(lidar_points_with_beam_ids)\n",
    "visualize_beam_ids(augmented_points_final[:,:3], augmented_points_final[:,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
