{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Beam-ID for all points in PandaSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# CONFIGURATION\n",
    "DATA_PATH = os.path.join('buni','dataset','pandaset')\n",
    "SCENE_IDX = 3\n",
    "FRAME_IDX = 70\n",
    "GROUND_LABELS = np.array([6, 7, 8, 9, 10, 11, 12, 34, 35, 37, 38, 39])\n",
    "user_home = os.path.expanduser('~') \n",
    "dataset_path = os.path.join(user_home,DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandaset import DataSet\n",
    "import logging\n",
    "\n",
    "dataset = DataSet(dataset_path)\n",
    "scenes_with_semantic_labels = sorted(dataset.sequences(with_semseg=True), key=int)\n",
    "print(f\"List of sequences available with semantic segmentation:\\n{scenes_with_semantic_labels}\")\n",
    "scene = dataset[scenes_with_semantic_labels[SCENE_IDX]]\n",
    "print(f\"Selected scene/sequence: {scenes_with_semantic_labels[SCENE_IDX]}\")\n",
    "scene.load_lidar()\n",
    "scene.load_semseg()\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.info(f\"Loaded scene {SCENE_IDX} with frame {FRAME_IDX}\")\n",
    "lidar_data = scene.lidar.data[FRAME_IDX]\n",
    "lidar_poses = scene.lidar.poses[FRAME_IDX]\n",
    "labels = scene.semseg.data[FRAME_IDX]\n",
    "\n",
    "from general_utils import pandaset_utils as pdutils\n",
    "from general_utils import gen_utils\n",
    "\n",
    "gen_utils.check_type(lidar_data,\"lidar_data\", logger)\n",
    "gen_utils.check_type(labels,\"labels\", logger)\n",
    "\n",
    "lidar_data, lidar_labels = pdutils.cleanup_lidar_data_and_labels(lidar_data, labels, lidar_poses,logger)\n",
    "\n",
    "logger.info(f\"Shape of lidar_data before reshaping: {lidar_data.shape}\")\n",
    "gen_utils.check_type(lidar_data,\"lidar_data\",logger)\n",
    "lidar_points = lidar_data.iloc[:,:3].to_numpy()\n",
    "lidar_points = lidar_points.astype('float64')\n",
    "logger.info(f\"Shape of lidar_data after reshaping: {lidar_points.shape}\")\n",
    "gen_utils.check_type(lidar_points,\"lidar_points\",logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming points is an Nx3 array with columns [x, y, z] representing the point cloud\n",
    "def assign_beam_ids(points):\n",
    "    # Calculate elevation for each point\n",
    "    # Elevation = arctan(z / sqrt(x^2 + y^2))\n",
    "    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "    elevations = np.arctan2(z, np.sqrt(x**2 + y**2))\n",
    "\n",
    "    # Find max and min elevation values\n",
    "    min_elevation = np.min(elevations)\n",
    "    max_elevation = np.max(elevations)\n",
    "\n",
    "    # Create 64 bins between min and max elevation\n",
    "    bins = np.linspace(min_elevation, max_elevation, 65)\n",
    "\n",
    "    # Assign each point to the closest bin\n",
    "    beam_ids = np.digitize(elevations, bins) - 1\n",
    "    beam_ids = np.clip(beam_ids, 0, 63)  # Ensure beam IDs are within the range [0, 63]\n",
    "\n",
    "    return beam_ids\n",
    " \n",
    "# Example usage\n",
    "# Replace 'points' with your actual point cloud data\n",
    "# points = np.array([...])  # Nx3 array of points\n",
    "# beam_ids = assign_beam_ids(points)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def assign_quantile_beam_ids(points, num_bins=64):\n",
    "    # Calculate elevations for each point\n",
    "    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "    elevations = np.arctan2(z, np.sqrt(x**2 + y**2))\n",
    "    \n",
    "    # Create bins based on quantiles to balance the number of points per bin\n",
    "    bins = np.percentile(elevations, np.linspace(0, 100, num_bins + 1))\n",
    "    beam_ids = np.digitize(elevations, bins) - 1\n",
    "    beam_ids = np.clip(beam_ids, 0, num_bins - 1)\n",
    "\n",
    "    # Reshape the beam_ids array to have shape (n, 1)\n",
    "    beam_ids = beam_ids.reshape(-1, 1)\n",
    "\n",
    "    return beam_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.colors as mcolors\n",
    "# import open3d as o3d\n",
    "# def visualize_beam_ids(lidar_points, beam_ids):\n",
    "\n",
    "#     # Create a point cloud in Open3D and assign colors based on beam IDs\n",
    "#     pcd = o3d.geometry.PointCloud()\n",
    "#     pcd.points = o3d.utility.Vector3dVector(lidar_points)\n",
    "\n",
    "#     # Use a discrete colormap with enough unique colors\n",
    "#     unique_beam_ids = np.unique(beam_ids)\n",
    "#     n_unique_beam_ids = len(unique_beam_ids)\n",
    "\n",
    "#     # Generate a colormap with N unique colors\n",
    "#     colors_list = list(mcolors.CSS4_COLORS.values())  # Get a large list of CSS colors\n",
    "#     if n_unique_beam_ids > len(colors_list):\n",
    "#         raise ValueError(\"Not enough unique colors available. Increase the color list or choose another colormap.\")\n",
    "\n",
    "#     # Create a color dictionary that maps each beam ID to a unique color\n",
    "#     beam_id_to_color = {beam_id: colors_list[i % len(colors_list)] for i, beam_id in enumerate(unique_beam_ids)}\n",
    "\n",
    "#     # Map the beam IDs to the corresponding colors\n",
    "#     colors = np.array([mcolors.to_rgb(beam_id_to_color[beam_id]) for beam_id in beam_ids])\n",
    "\n",
    "#     # Set the colors to the point cloud\n",
    "#     pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "#     # Visualize the point cloud\n",
    "#     o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import open3d as o3d\n",
    "\n",
    "def visualize_beam_ids3(lidar_points, beam_ids):\n",
    "    # Ensure beam_ids has the correct shape\n",
    "    if beam_ids.shape[1] != 1:\n",
    "        raise ValueError(\"Beam IDs must be an (n, 1) array.\")\n",
    "    \n",
    "    # Reshape beam_ids to be a flat array for color mapping\n",
    "    beam_ids = beam_ids.flatten()\n",
    "    \n",
    "    # Check shapes for debugging\n",
    "    print(\"lidar_points shape:\", lidar_points.shape)\n",
    "    print(\"beam_ids shape after flattening:\", beam_ids.shape)\n",
    "\n",
    "    # Ensure beam_ids has the correct length\n",
    "    if lidar_points.shape[0] != beam_ids.shape[0]:\n",
    "        raise ValueError(\"Error: The number of beam IDs does not match the number of lidar points.\")\n",
    "\n",
    "    # Create a point cloud in Open3D and assign colors based on beam IDs\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(lidar_points)\n",
    "\n",
    "    # Use the 'hsv' colormap from matplotlib for better distinction of beam IDs\n",
    "    cmap = plt.get_cmap('hsv')\n",
    "\n",
    "    # Normalize beam IDs to fit the colormap range\n",
    "    norm = mcolors.Normalize(vmin=0, vmax=63)  # Assuming beam IDs are in the range [0, 63]\n",
    "\n",
    "    # Assign colors based on the normalized beam IDs\n",
    "    colors = cmap(norm(beam_ids))[:, :3]  # Extract RGB channels\n",
    "    colors = colors.reshape(-1, 3)  # Ensure the shape is (n, 3)\n",
    "\n",
    "    # Check color array shape for debugging\n",
    "    print(\"colors shape:\", colors.shape)\n",
    "\n",
    "    # Set the colors to the point cloud\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "    # Visualize the point cloud with a larger point size\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "\n",
    "    # Set rendering options for better visualization\n",
    "    render_option = vis.get_render_option()\n",
    "    render_option.point_size = 2.0  # Increase point size for better visibility\n",
    "    render_option.background_color = np.array([1, 1, 1])  # Set background color to white for contrast\n",
    "\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "\n",
    "# Example usage\n",
    "# lidar_points = np.array([[x1, y1, z1], [x2, y2, z2], ...])  # n x 3 array of points\n",
    "# beam_ids = np.array([[id1], [id2], [id3], ...])  # n x 1 array of beam IDs\n",
    "# visualize_beam_ids3(lidar_points, beam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_ids = assign_quantile_beam_ids(lidar_points)\n",
    "\n",
    "visualize_beam_ids3(lidar_points,beam_ids)\n",
    "\n",
    "lidar_points_with_beam_ids = np.hstack((lidar_points, beam_ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray-Dropping\n",
    "\n",
    "+ `beam_ids` is a numpy array. \n",
    "+ Joint `beam_ids` with `lidar_points` to get `lidar_points_with_beam_ids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_beam_drop(points):\n",
    "    # Randomly select a beam drop ratio from [1, 2, 3]\n",
    "    beam_drop_ratio = np.random.choice([1, 2, 3])\n",
    "    # beam_drop_ratio = 3\n",
    "    print(f\"Beam drop ratio: {beam_drop_ratio}\")\n",
    "    # Randomly select a starting beam index\n",
    "    start_index = np.random.randint(0, beam_drop_ratio)\n",
    "\n",
    "    # Apply the ray-dropping condition\n",
    "    mask = (points[:, 3] - start_index) % beam_drop_ratio == 0\n",
    "    return points[mask]\n",
    "\n",
    "\n",
    "def spherical_coordinates_conversion(points):\n",
    "    # Convert to spherical coordinates\n",
    "    x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "    radial_dist = np.sqrt(x**2 + y**2 + z**2)\n",
    "    theta = np.arctan2(y, x)  # azimuth\n",
    "    phi = np.arcsin(z / radial_dist)  # elevation\n",
    "\n",
    "    # Filter out points with radial distance < 0.1\n",
    "    valid_mask = radial_dist > 0.1\n",
    "\n",
    "    return np.vstack((theta[valid_mask], phi[valid_mask], radial_dist[valid_mask])).T, valid_mask\n",
    "\n",
    "def random_spherical_drop(points, valid_mask):\n",
    "    # Sample spherical resolutions for theta and phi\n",
    "    spherical_resolutions = np.random.choice([600, 900, 1200, 1500])\n",
    "    \n",
    "    # Convert theta and phi to grid cells\n",
    "    spherical_coords, valid_mask = spherical_coordinates_conversion(points)\n",
    "    theta_grid = (spherical_coords[:, 0] * spherical_resolutions).astype(int)\n",
    "    phi_grid = (spherical_coords[:, 1] * spherical_resolutions).astype(int)\n",
    "    \n",
    "    # Randomly sample spherical drop ratio\n",
    "    spherical_drop_ratio = np.random.choice([1, 2])\n",
    "    # spherical_drop_ratio = 2\n",
    "    print(f\"Spherical drop ratio: {spherical_drop_ratio}\")\n",
    "    # Apply the ray-dropping condition in the spherical coordinates\n",
    "    theta_mask = (theta_grid % spherical_drop_ratio == 0)\n",
    "    phi_mask = (phi_grid % spherical_drop_ratio == 0)\n",
    "    \n",
    "    # Combine the valid_mask from earlier with spherical mask\n",
    "    combined_mask = valid_mask & theta_mask & phi_mask\n",
    "    return points[combined_mask]\n",
    "\n",
    "\n",
    "def ray_dropping_augmentation(points):\n",
    "    # Step 1: Random beam drop\n",
    "    points_after_beam_drop = random_beam_drop(points)\n",
    "    \n",
    "    # Step 2: Spherical drop\n",
    "    points_after_spherical_drop = random_spherical_drop(points_after_beam_drop, np.ones(points_after_beam_drop.shape[0], dtype=bool))\n",
    "    \n",
    "    return points_after_spherical_drop\n",
    "\n",
    "# Example usage\n",
    "augmented_points_final = ray_dropping_augmentation(lidar_points_with_beam_ids)\n",
    "beam_ids = augmented_points_final[:,3].reshape(-1,1)\n",
    "visualize_beam_ids3(augmented_points_final[:,:3], beam_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
